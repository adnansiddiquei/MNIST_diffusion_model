# M2: Applications of Machine Learning - Coursework Assignment
## Table of Contents
1. [Training the models](#run)
2. [Generating the plots](#plots)
3. [Documentation](#docs)
4. [Report](#report)
5. [Use of auto-generation tools](#auto)

## <a name="run"></a> 1. Training the models
Clone the repository and then run
```bash
make run
```
in your terminal, within the root of this repo. This will create and load the Docker container, mount the necessary
directories, create the environment and open an interactive terminal in the running Docker container.

Note you may follow these instructions on either Docker or your local machine,
Docker takes a very long time to train the models as it does not have access to the GPU. If you would like to train the
model on your local machine, skip the above step and simply `make conda-env` to create the conda environment and then
`conda activate as3438_m2cw` to activate the environment.

There are 3 scripts that need to be run, that will train 5 models:
```bash
python src/ddpm_train.py  # trains the 3 DDPM models discussed in Section (2).
python src/fashion_mnist_train.py  # trains the custom degradation model discussed in Section (3).
python src/mnist_classifier_train.py  # trains the MNIST classifier for the FMD score, Section (2)
```

All of these will train the models and save them to the `outputs` directory. All the models are trained for 100 epochs,
and all 100 `state_dicts` as well as the losses are saved into the `outputs` directory. The `state_dicts` are used after
the fact to load each model up and generate the relevant plots and analysis.

If you run these scripts in the Docker container, the `outputs` directory will be mounted so they will be saved back to
your local machine. You can delete the container and image by runninng `make clean-docker`.

## <a name="plots"></a> 2. Generating the plots
All the figures that are used in the report are generated from the two `.ipynb` files in the `src/plots` directory.
Once the models have finished training, you can run these notebooks to generate the plots.
The notebooks need to be run sequentially, as the second notebook relies on some outputs from the first notebook.

All the plots are output directly into `report/figures`.

## <a name="docs"></a> 3. Documentation
The documentation is generated by sphinx. To view the documentation run
```bash
cd docs
make html
```
And then open `docs/build/html/index.html` in your browser.

You can do this from either your local machine or the Docker container, the `docs` folder is mounted so if you generate
the docs in the container, they will be synced back to your local machine so they can be opened in your browser.

## <a name="report"></a> 4. Report
The report is located at [report/out/main.pdf](report/out/main.pdf).

## <a name="auto"></a> 5. Use of auto-generation tools
Auto-generation tools, specifically ChatGPT and co-pilot were used in a couple of instances throughout the project as
detailed here:
 - Co-pilot was used to assist in writing a lot of the docstrings via tab completion. These were amended as required.
 - ChatGPT was used to assist in creating the `utils.calculate_fid` function to compute the Frechet distance between two
 vectors.
 - ChatGPT was used to assist in a few matplotlib plot formatting queries.
