{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:22:56.466683Z",
     "start_time": "2024-03-20T21:22:54.666398Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from utils import ddpm_schedules, CNNBlock, CNN, DDPM, CNNClassifier\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook trains an MNIST classifier using the existing CNNBlock class. The code for the CNNClassifier is in `utils`. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca7bbb5ba67622a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "\n",
    "train_dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "test_dataset = MNIST(\"./data\", train=False, download=True, transform=tf)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:22:56.494070Z",
     "start_time": "2024-03-20T21:22:56.467655Z"
    }
   },
   "id": "f1570cff2a1b3181",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNClassifier(1, (32, 64, 64, 32), 10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "ddpm, optim, train_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optim, train_dataloader, test_dataloader\n",
    ")\n",
    "\n",
    "# state_dict = torch.load(\"./models/_mnist_classifier_20.pth\")\n",
    "# model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:23:43.731949Z",
     "start_time": "2024-03-20T21:23:43.696526Z"
    }
   },
   "id": "97d8b7ed405c128d",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training loop is below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93f520d95d1676a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(train_dataloader)  # Wrap our loop with a visual progress bar\n",
    "\n",
    "    for x, label in pbar:\n",
    "        optim.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, label)\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        avg_loss = np.average(train_loss[-100:])\n",
    "        pbar.set_description(f\"loss: {avg_loss:.3g}\")  # Show running average of loss in progress bar\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_loss_batch = []\n",
    "    correct_count = 0\n",
    "\n",
    "    for x, label_test in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            preds_test = model(x)\n",
    "            loss_test = loss_fn(preds_test, label_test)\n",
    "            test_loss_batch.append(loss_test.item())\n",
    "\n",
    "            # Calculate number of correct predictions\n",
    "            _, predicted = torch.max(preds_test.data, 1)\n",
    "            correct_count += (predicted == label_test).sum().item()\n",
    "\n",
    "    avg_test_loss = np.average(test_loss_batch)\n",
    "    test_loss.append(avg_test_loss)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / len(test_dataset)\n",
    "\n",
    "    print(f'Epoch [{i+1}/{n_epoch}], Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2%}')\n",
    "\n",
    "    torch.save(ddpm.state_dict(), f\"./models/mnist_classifier_{i}.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:23:27.547718Z",
     "start_time": "2024-03-20T21:23:27.545210Z"
    }
   },
   "id": "18b5f136fe547b65",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ce830b2f2a1a1ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
