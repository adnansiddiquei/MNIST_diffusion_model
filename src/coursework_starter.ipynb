{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOqtixLa1y-b"
   },
   "source": [
    "The following example notebook implements standard diffusion\n",
    "with a simple CNN model to generate realistic MNIST digits.\n",
    "\n",
    "This is a modified implementation of `minDiffusion`\n",
    "which implements [DDPM](https://arxiv.org/abs/2006.11239)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example notebook,\n",
    "install requirements as in `requirements.txt` (for example, `pip install -r requirements.txt`).\n",
    "You may also wish to follow system-dependent PyTorch instructions\n",
    "[here](https://pytorch.org/) to install accelerated\n",
    "versions of PyTorch, but note they are not needed\n",
    "(I am testing this on my laptop).\n",
    "\n",
    "If you do use accelerated hardware, make sure that your code\n",
    "is still compatible with CPU-only installs.\n",
    "\n",
    "First, let's create a folder to store example images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaJ7P2ft2G6j",
    "outputId": "7ce57688-755a-431b-c73d-2e32301824ea",
    "ExecuteTime": {
     "end_time": "2024-03-19T00:22:30.674660Z",
     "start_time": "2024-03-19T00:22:30.540248Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "50FGtZsk1y-b",
    "ExecuteTime": {
     "end_time": "2024-03-21T16:22:55.192099Z",
     "start_time": "2024-03-21T16:22:53.575736Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from utils import ddpm_schedules, CNNBlock, CNN, DDPM, save_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this on MNIST. We perform some basic preprocessing, and set up the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a6jMrCRa1y-d",
    "ExecuteTime": {
     "end_time": "2024-03-21T16:22:55.210978Z",
     "start_time": "2024-03-21T16:22:55.192997Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the train function."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_ddpm(\n",
    "        ddpm: nn.Module, \n",
    "        optim: torch.optim.Optimizer, \n",
    "        dataloader: DataLoader, \n",
    "        accelerator: Accelerator, \n",
    "        save_folder: str,\n",
    "        n_epoch: int = 100,\n",
    "        start_epoch: int = 0\n",
    "    ):\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(n_epoch):\n",
    "        ddpm.train()\n",
    "    \n",
    "        pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
    "        for x, _ in pbar:\n",
    "            optim.zero_grad()\n",
    "    \n",
    "            loss = ddpm(x)\n",
    "    \n",
    "            loss.backward()\n",
    "            # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
    "    \n",
    "            losses.append(loss.item())\n",
    "            avg_loss = np.average(losses[min(len(losses)-100, 0):])\n",
    "            pbar.set_description(f\"loss: {avg_loss:.3g}\")  # Show running average of loss in progress bar\n",
    "    \n",
    "            optim.step()\n",
    "    \n",
    "        ddpm.eval()\n",
    "        with torch.no_grad():\n",
    "            xh = ddpm.sample(16, (1, 28, 28), accelerator.device)  # Can get device explicitly with `accelerator.device`\n",
    "            grid = make_grid(xh, nrow=4)\n",
    "    \n",
    "            # Save samples to `./contents` directory\n",
    "            save_image(grid, f\"./{save_folder}/ddpm_sample_{start_epoch + i:04d}.png\")\n",
    "    \n",
    "            # save model\n",
    "            torch.save(ddpm.state_dict(), f\"./{save_folder}/ddpm_mnist_{start_epoch + i}.pth\")\n",
    "            \n",
    "    save_pickle(losses, f\"./{save_folder}/ddpm_mnist_losses_{start_epoch}.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:28:58.772070Z",
     "start_time": "2024-03-21T17:28:58.767280Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define each of the models we will be testing.\n",
    "\n",
    "We essentially just vary the noise schedule but keep it linear in all of them. We keep the initial noise the same but change the final noise so that we add noise at a quicker or slower rate.\n",
    "\n",
    "Here, we use HuggingFace's `accelerate` library, which abstracts away all the `.to(device)` calls for us.\n",
    "This lets us focus on the model itself rather than data movement.\n",
    "It also does a few other tricks to speed up calculations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# this is the default model\n",
    "accelerator_1 = Accelerator()\n",
    "gt_1 = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "ddpm_1 = DDPM(gt=gt_1, betas=(1e-4, 0.02), n_T=1000)\n",
    "optim_1 = torch.optim.Adam(ddpm_1.parameters(), lr=2e-4)\n",
    "ddpm_1, optim_1, dataloader_1 = accelerator_1.prepare(ddpm_1, optim_1, dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:39:12.244938Z",
     "start_time": "2024-03-21T17:39:12.226982Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accelerator_2 = Accelerator()\n",
    "gt_2 = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "ddpm_2 = DDPM(gt=gt_2, betas=(1e-4, 0.1), n_T=200)\n",
    "optim_2 = torch.optim.Adam(ddpm_2.parameters(), lr=2e-4)\n",
    "ddpm_2, optim_2, dataloader_2 = accelerator_2.prepare(ddpm_2, optim_2, dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:39:12.525475Z",
     "start_time": "2024-03-21T17:39:12.507482Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accelerator_3 = Accelerator()\n",
    "gt_3 = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "ddpm_3 = DDPM(gt=gt_3, betas=(1e-4, 0.004), n_T=5000)\n",
    "optim_3 = torch.optim.Adam(ddpm_3.parameters(), lr=2e-4)\n",
    "ddpm_3, optim_3, dataloader_3 = accelerator_3.prepare(ddpm_3, optim_3, dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:39:12.937712Z",
     "start_time": "2024-03-21T17:39:12.922644Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we train the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.114: 100%|██████████| 468/468 [00:29<00:00, 15.67it/s]\n",
      "loss: 0.0804: 100%|██████████| 468/468 [00:28<00:00, 16.43it/s]\n",
      "loss: 0.0666: 100%|██████████| 468/468 [00:28<00:00, 16.37it/s]\n",
      "loss: 0.0586: 100%|██████████| 468/468 [00:28<00:00, 16.29it/s]\n",
      "loss: 0.0532: 100%|██████████| 468/468 [00:28<00:00, 16.35it/s]\n",
      "loss: 0.0492: 100%|██████████| 468/468 [00:28<00:00, 16.37it/s]\n",
      "loss: 0.0461: 100%|██████████| 468/468 [00:28<00:00, 16.44it/s]\n",
      "loss: 0.0437: 100%|██████████| 468/468 [00:28<00:00, 16.29it/s]\n",
      "loss: 0.0417: 100%|██████████| 468/468 [00:28<00:00, 16.53it/s]\n",
      "loss: 0.04: 100%|██████████| 468/468 [00:28<00:00, 16.43it/s]  \n",
      "loss: 0.0385: 100%|██████████| 468/468 [00:28<00:00, 16.38it/s]\n",
      "loss: 0.0373: 100%|██████████| 468/468 [00:28<00:00, 16.40it/s]\n",
      "loss: 0.0362: 100%|██████████| 468/468 [00:28<00:00, 16.36it/s]\n",
      "loss: 0.0352: 100%|██████████| 468/468 [00:28<00:00, 16.57it/s]\n",
      "loss: 0.0343: 100%|██████████| 468/468 [00:28<00:00, 16.54it/s]\n",
      "loss: 0.0335: 100%|██████████| 468/468 [00:28<00:00, 16.47it/s]\n",
      "loss: 0.0328: 100%|██████████| 468/468 [00:28<00:00, 16.22it/s]\n",
      "loss: 0.0322: 100%|██████████| 468/468 [00:28<00:00, 16.54it/s]\n",
      "loss: 0.0316: 100%|██████████| 468/468 [00:28<00:00, 16.43it/s]\n",
      "loss: 0.0311: 100%|██████████| 468/468 [00:28<00:00, 16.55it/s]\n",
      "loss: 0.0306: 100%|██████████| 468/468 [00:28<00:00, 16.56it/s]\n",
      "loss: 0.0301: 100%|██████████| 468/468 [00:28<00:00, 16.46it/s]\n",
      "loss: 0.0297: 100%|██████████| 468/468 [00:28<00:00, 16.30it/s]\n",
      "loss: 0.0292: 100%|██████████| 468/468 [00:28<00:00, 16.50it/s]\n",
      "loss: 0.0289: 100%|██████████| 468/468 [00:28<00:00, 16.50it/s]\n",
      "loss: 0.0285: 100%|██████████| 468/468 [00:27<00:00, 17.00it/s]\n",
      "loss: 0.0282: 100%|██████████| 468/468 [00:27<00:00, 16.90it/s]\n",
      "loss: 0.0279: 100%|██████████| 468/468 [00:27<00:00, 16.77it/s]\n",
      "loss: 0.0276: 100%|██████████| 468/468 [00:28<00:00, 16.70it/s]\n",
      "loss: 0.0273: 100%|██████████| 468/468 [00:29<00:00, 16.12it/s]\n",
      "loss: 0.0271: 100%|██████████| 468/468 [00:28<00:00, 16.17it/s]\n",
      "loss: 0.0268: 100%|██████████| 468/468 [00:28<00:00, 16.34it/s]\n",
      "loss: 0.0266: 100%|██████████| 468/468 [00:28<00:00, 16.44it/s]\n",
      "loss: 0.0264: 100%|██████████| 468/468 [00:28<00:00, 16.45it/s]\n",
      "loss: 0.0261: 100%|██████████| 468/468 [00:28<00:00, 16.23it/s]\n",
      "loss: 0.0259: 100%|██████████| 468/468 [00:29<00:00, 16.07it/s]\n",
      "loss: 0.0258: 100%|██████████| 468/468 [00:29<00:00, 16.00it/s]\n",
      "loss: 0.0256: 100%|██████████| 468/468 [00:29<00:00, 16.07it/s]\n",
      "loss: 0.0254: 100%|██████████| 468/468 [00:29<00:00, 15.99it/s]\n",
      "loss: 0.0252: 100%|██████████| 468/468 [00:29<00:00, 16.10it/s]\n",
      "loss: 0.0251: 100%|██████████| 468/468 [00:29<00:00, 16.13it/s]\n",
      "loss: 0.0249: 100%|██████████| 468/468 [00:29<00:00, 16.12it/s]\n",
      "loss: 0.0248:  49%|████▉     | 231/468 [00:14<00:13, 17.68it/s]"
     ]
    }
   ],
   "source": [
    "!mkdir -p contents_2\n",
    "train_ddpm(ddpm_2, optim_2, dataloader_2, accelerator_2, \"contents_2\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-21T17:39:18.538561Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!mkdir -p contents_3\n",
    "train_ddpm(ddpm_3, optim_3, dataloader_3, accelerator_3, \"contents_3\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
